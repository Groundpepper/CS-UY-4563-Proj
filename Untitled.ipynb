{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "857cf4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, SGDClassifier, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import IPython\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e386722-dedb-4efc-89ce-5505562240b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_ML():\n",
    "    \"\"\"\n",
    "    reshapes image and coordinate data; returns X and Y for ML\n",
    "    \"\"\"\n",
    "    train_images, train_coords = list(), list()\n",
    "    with open('coordinates.txt', 'r') as f:\n",
    "        for line in tqdm(f):\n",
    "            lat, lon, image_path = line.split(',')\n",
    "            train_coords.append([float(lat), float(lon)])\n",
    "            image_path = image_path[1:-1]\n",
    "            image_array = np.array(Image.open(image_path))\n",
    "            train_images.append(image_array)\n",
    "    return np.asarray(train_images), np.asarray(train_coords)\n",
    "\n",
    "\n",
    "def compare_results(actual_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    text here\n",
    "    \"\"\"\n",
    "    accuracy_list, points_list = list(), list()\n",
    "    for item_ind in range(len(actual_labels)):\n",
    "        lat_difference = abs(actual_labels[item_ind][0] - predicted_labels[item_ind][0])\n",
    "        lon_difference = abs(actual_labels[item_ind][1] - predicted_labels[item_ind][1])\n",
    "        total_difference_miles = lat_difference * 69 + lon_difference * 54.6 # 1 lat ~ 69 mi; 1 lon ~ 54.6 mi\n",
    "        points = 5000 * (math.e ** (-1 * total_difference_miles / 4000)) # Russia's span is 4500 mi\n",
    "        points_list.append(points)\n",
    "        accuracy_list.append(points / 5000 * 100)\n",
    "    return str(round(sum(accuracy_list) / len(accuracy_list))) + '%', sum(points_list) / len(points_list)\n",
    "\n",
    "\n",
    "def show_error_distribution(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    text here\n",
    "    \"\"\"\n",
    "    error_vals = list()\n",
    "    for ind in range(len(y_test)):\n",
    "        miles_apart = ((abs(y_test[ind][0] - y_pred[ind][0]) ** 2 + abs(y_test[ind][1] - y_pred[ind][1]) ** 2)) ** (1/2)\n",
    "        error_vals.append(round(miles_apart))\n",
    "    plt.xlabel('Distance Apart (mi)')\n",
    "    plt.ylabel(\"Number of Guesses\")\n",
    "    plt.bar(error_vals, [error_vals.count(v) for v in error_vals])\n",
    "\n",
    "\n",
    "def KNN_test(X_train, y_train, X_test, n_neighbors):\n",
    "    \"\"\"\n",
    "    ~83%\n",
    "    runtime: <1 hr based on n_neighbors\n",
    "    \"\"\"\n",
    "    if len(X_train.shape) != 2 or len(X_test.shape) != 2:\n",
    "        X_train = X_train.reshape(len(X_train), -1)\n",
    "        X_test = X_test.reshape(len(X_test), -1)\n",
    "    X_train = X_train.astype(int)\n",
    "    y_train = y_train.astype(int)\n",
    "    X_test = X_test.astype(int)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    return neigh.predict(X_test)\n",
    "\n",
    "\n",
    "def display_KNN_graph(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    text here\n",
    "    \"\"\"\n",
    "    if len(X_train.shape) != 2 or len(X_test.shape) != 2:\n",
    "        X_train = X_train.reshape(len(X_train), -1)\n",
    "        X_test = X_test.reshape(len(X_test), -1)\n",
    "    x, y = list(), list()\n",
    "    for i in tqdm(range(5, len(X_train) // 10, 5)):\n",
    "        y_pred = KNN_test(X_train, y_train, X_test, i)\n",
    "        x.append(i)\n",
    "        y.append(float(compare_results(y_test, y_pred)[0][:-1]))\n",
    "    plt.xlabel('Number of Neighbors')\n",
    "    plt.ylabel(\"Percentage Accuracy\")\n",
    "    plt.plot(x, y)\n",
    "\n",
    "\n",
    "def linreg_test(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    ~80%\n",
    "    runtime: ~10m\n",
    "    \"\"\"\n",
    "    if len(X_train.shape) != 2 or len(X_test.shape) != 2:\n",
    "        X_train = X_train.reshape(len(X_train), -1)\n",
    "        X_test = X_test.reshape(len(X_test), -1)\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    return linreg.predict(X_test)\n",
    "\n",
    "\n",
    "def logreg_test(X_train, y_train, X_test, penalty):\n",
    "    \"\"\"\n",
    "    penalty l2:    82%\n",
    "    penalty None:  78%\n",
    "    Runtime:  45m\n",
    "    \"\"\"\n",
    "    if len(X_train.shape) != 2 or len(X_test.shape) != 2:\n",
    "        X_train = X_train.reshape(len(X_train), -1)\n",
    "        X_test = X_test.reshape(len(X_test), -1)\n",
    "    X_train = X_train.astype(int)\n",
    "    y_train = y_train.astype(int)\n",
    "    X_test = X_test.astype(int)\n",
    "    lat_clf, lon_clf = SGDClassifier(penalty=penalty), SGDClassifier(penalty=penalty)\n",
    "    lat_clf.fit(X_train, [c[0] for c in y_train])\n",
    "    lon_clf.fit(X_train, [c[1] for c in y_train])\n",
    "    lat_predicted, lon_predicted = lat_clf.predict(X_test), lon_clf.predict(X_test)\n",
    "    return [[lat_predicted[i], lon_predicted[i]] for i in range(len(lat_predicted))]\n",
    "    \n",
    "\n",
    "def sanity_test():\n",
    "    counter = 0\n",
    "    with open('coordinates.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            if line.split('screenshots/')[-1][:-1] not in os.listdir('screenshots'):\n",
    "                print(line)\n",
    "            counter += 1\n",
    "    len_screenshots = len(list(os.listdir('screenshots'))) - 1\n",
    "    print(counter == len_screenshots)\n",
    "    print(counter, '==', len_screenshots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f78e6e-ffdb-49fc-8738-39cae771a0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "990it [00:18, 54.90it/s]\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = get_data_for_ML()\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f0b7fc-6579-45a8-94ec-e105315727be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccafc7e5-2806-4f4c-9ee1-d2fb55f30618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27bd37f-7547-4651-8301-b85d4f5caec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3dc2a578-ff68-4115-a6bd-8769b4f728b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_a(y_train, y_test, y_pred):\n",
    "    for ind in range(len(y_test)):\n",
    "        plt.scatter([a[1] for a in y_train], [a[0] for a in y_train])\n",
    "        plt.scatter([38], [56], label='Moscow', color='black')\n",
    "        plt.scatter([30], [60], label='St. Petersberg', color='black')\n",
    "        plt.scatter([44], [48], label='Volgograd', color='black')\n",
    "        plt.scatter([131], [43], label='Vladivostok', color='black')\n",
    "        plt.scatter([y_test[ind][1]], [y_test[ind][0]], color='lightgreen') # ACTUAL VALUE\n",
    "        plt.scatter([y_pred[ind][1]], [y_pred[ind][0]], color='orange') # PREDICTED VALUE\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        time.sleep(1)\n",
    "        IPython.display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172978bc-386c-441e-989b-5693da9cf3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_a(y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c9f8e2-8f0f-48fe-b140-6feb53a15ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525a7775-21fb-4107-9399-f8399c3d1f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc1600f-ac97-4411-bfd5-a0abf9467b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_KNN_graph(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746be0f6-8d8a-4832-be8e-989e2f29c680",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = KNN_test(X_train, y_train, X_test, 40)\n",
    "print(compare_results(y_test, y_pred))\n",
    "show_error_distribution(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3309255-b46b-4aee-b844-d60cd3c9936f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a144a2-01f3-4362-a8cf-91160f2d7a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linreg_test(X_train, y_train, X_test)\n",
    "print(compare_results(y_test, y_pred))\n",
    "show_error_distribution(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf66e26-7efc-4d19-b583-8d6c9e3d494c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f96313-d9ae-471f-9eba-b3739475223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg_test(X_train, y_train, X_test, 'l2')\n",
    "print(compare_results(y_test, y_pred))\n",
    "show_error_distribution(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44b7e50-9cce-45c6-950f-872a11be7cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da2732-779e-49d5-9c7c-4e447e75ae43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3180206-74bf-4c84-9f11-fa7a92a67ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2c4a7f-4afd-432c-8181-95b87ae09bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081707a8-ff2c-4b02-a5a2-ff32073a774b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a23a1-d3bc-479b-b6f8-9f815e89a840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531383fc-182b-4f7c-8a08-0ba593ce41af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60413f67-61c7-43fc-99d4-6a9d7a741668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b46c55-d059-4eca-8e48-92b1c7f2cbee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab399d2e-f2c2-4955-bae9-4348984d8762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23665a61-8842-4361-848b-7672d2db3197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf38f4f-ddf4-4303-a633-bee3918802c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, output_layer_count):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(596 * 1036 * 4, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, output_layer_count))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 596 * 1036 * 4)\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "def train_neutral_network(net, train_dl: torch.utils.data.DataLoader, test_dl: torch.utils.data.DataLoader, lr: float, n_epochs: int):\n",
    "    \"\"\"\n",
    "    text here\n",
    "    \"\"\"\n",
    "    Loss = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=1)\n",
    "    # optimizer = torch.optim.Adam()\n",
    "    # optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=1, nesterov=True)\n",
    "    train_loss_history, test_loss_history = list(), list()\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0.0\n",
    "        test_loss = 0.0\n",
    "        for i, data in enumerate(train_dl):\n",
    "            images, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            predicted_output = net(images)\n",
    "            fit = Loss(predicted_output, labels)\n",
    "            fit.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += fit.item()\n",
    "        for i, data in enumerate(test_dl):\n",
    "            with torch.no_grad():\n",
    "                images, labels = data\n",
    "                predicted_output = net(images)\n",
    "                fit = Loss(predicted_output, labels)\n",
    "                test_loss += fit.item()\n",
    "        train_loss = train_loss / len(train_dl)\n",
    "        test_loss = test_loss / len(test_dl)\n",
    "        train_loss_history.append(train_loss)\n",
    "        test_loss_history.append(test_loss)\n",
    "        print('Epoch {}, \\tTrain loss {}, \\tTest loss {}'.format(epoch, round(train_loss, 2), round(test_loss, 2)))\n",
    "    return net, train_loss_history, test_loss_history\n",
    "    \n",
    "\n",
    "def evaluate(net: Net, dataloader: torch.utils.data.DataLoader):\n",
    "    total, correct = 0, 0\n",
    "    net.eval()\n",
    "    for data in dataloader:\n",
    "        images, labels = data\n",
    "        predicted_output = net(images)\n",
    "        _, predicted_labels = torch.max(predicted_output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted_labels == labels).sum().item()\n",
    "    return 100 * correct/total\n",
    "\n",
    "\n",
    "def evaluate2(net: Net, dataloader: torch.utils.data.DataLoader):\n",
    "    net.eval()\n",
    "    d_list = list()\n",
    "    for data in dataloader:\n",
    "        images, labels = data\n",
    "        predicted_output = net(images)\n",
    "        _, predicted_labels = torch.max(predicted_output, 1)\n",
    "        differences = [abs(predicted_labels[i] - labels[i]) for i in range(len(predicted_labels))]\n",
    "        d_list.append(sum(differences) / len(differences))\n",
    "    return sum(d_list) / len(d_list)\n",
    "\n",
    "\n",
    "def show_loss_graph(n_epochs, train_loss_history, test_loss_history):\n",
    "    plt.plot(np.arange(n_epochs), train_loss_history, '-', linewidth=3, label='Train error')\n",
    "    plt.plot(np.arange(n_epochs), test_loss_history, '-', linewidth=3, label='Test error')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "\n",
    "def make_minibatch_y(net_lat, net_lon, dataloader_lat, dataloader_lon):\n",
    "    net_lat.eval()\n",
    "    net_lon.eval()\n",
    "    lat_pred, lon_pred = list(), list()\n",
    "    lat_actual, lon_actual = list(), list()\n",
    "    for data in dataloader_lat:\n",
    "        images, labels = data\n",
    "        predicted_output = net_lat(images)\n",
    "        _, predicted_labels = torch.max(predicted_output, 1)\n",
    "        lat_pred += list(predicted_labels)\n",
    "        lat_actual += labels\n",
    "    for data in dataloader_lon:\n",
    "        images, labels = data\n",
    "        predicted_output = net_lon(images)\n",
    "        _, predicted_labels = torch.max(predicted_output, 1)\n",
    "        lon_pred += list(predicted_labels)\n",
    "        lon_actual += labels\n",
    "    y_test = np.asarray([[lat_actual[i], lon_actual[i]] for i in range(len(lat_actual))])\n",
    "    y_pred = np.asarray([[lat_pred[i], lon_pred[i]] for i in range(len(lat_pred))])\n",
    "    return y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "200b354f-c815-4746-8f3a-ed7df1252fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_lat = torch.utils.data.TensorDataset(torch.FloatTensor(X_train), torch.LongTensor([v[0] for v in y_train]))\n",
    "train_dl_lat = torch.utils.data.DataLoader(train_ds_lat, batch_size=64, shuffle=True)\n",
    "train_ds_lon = torch.utils.data.TensorDataset(torch.FloatTensor(X_train), torch.LongTensor([v[1] for v in y_train]))\n",
    "train_dl_lon = torch.utils.data.DataLoader(train_ds_lon, batch_size=64, shuffle=True)\n",
    "test_ds_lat = torch.utils.data.TensorDataset(torch.FloatTensor(X_test), torch.LongTensor([v[0] for v in y_test]))\n",
    "test_dl_lat = torch.utils.data.DataLoader(test_ds_lat, batch_size=64, shuffle=True)\n",
    "test_ds_lon = torch.utils.data.TensorDataset(torch.FloatTensor(X_test), torch.LongTensor([v[1] for v in y_test]))\n",
    "test_dl_lon = torch.utils.data.DataLoader(test_ds_lon, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3aba29-d76a-4815-bcd6-fb0c8b010218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, \tTrain loss 20.53, \tTest loss 13.61\n",
      "Epoch 1, \tTrain loss 10.3, \tTest loss 11.0\n",
      "Epoch 2, \tTrain loss 9.27, \tTest loss 10.48\n",
      "Epoch 3, \tTrain loss 8.62, \tTest loss 9.93\n",
      "Epoch 4, \tTrain loss 8.48, \tTest loss 10.81\n",
      "Epoch 5, \tTrain loss 8.48, \tTest loss 7.5\n",
      "Epoch 6, \tTrain loss 6.37, \tTest loss 8.62\n",
      "Epoch 7, \tTrain loss 6.29, \tTest loss 6.99\n",
      "Epoch 8, \tTrain loss 6.38, \tTest loss 8.32\n",
      "Epoch 9, \tTrain loss 6.55, \tTest loss 9.34\n",
      "Epoch 0, \tTrain loss 28.35, \tTest loss 18.3\n",
      "Epoch 1, \tTrain loss 16.58, \tTest loss 18.48\n",
      "Epoch 2, \tTrain loss 16.3, \tTest loss 17.21\n",
      "Epoch 3, \tTrain loss 15.76, \tTest loss 17.1\n",
      "Epoch 4, \tTrain loss 15.56, \tTest loss 17.65\n",
      "Epoch 5, \tTrain loss 14.78, \tTest loss 17.96\n"
     ]
    }
   ],
   "source": [
    "lr = 0.00000001\n",
    "n_epochs = 10\n",
    "\n",
    "net_lat, train_loss_history_lat, test_loss_history_lat = train_neutral_network(Net(64), train_dl_lat, test_dl_lat, lr, n_epochs)\n",
    "net_lon, train_loss_history_lon, test_loss_history_lon = train_neutral_network(Net(180), train_dl_lon, test_dl_lon, lr, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca607c4a-d225-4df5-a52e-fe10d4384662",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train acc = %0.2f, test acc = %0.2f' % (evaluate(net_lat, train_dl_lat), evaluate(net_lat, test_dl_lat)))\n",
    "print('Train dist error = %0.2f, test dist error = %0.2f' % (evaluate2(net_lat, train_dl_lat), evaluate2(net_lat, test_dl_lat)))\n",
    "\n",
    "print('Train acc = %0.2f, test acc = %0.2f' % (evaluate(net_lon, train_dl_lon), evaluate(net_lon, test_dl_lon)))\n",
    "print('Train dist error = %0.2f, test dist error = %0.2f' % (evaluate2(net_lon, train_dl_lon), evaluate2(net_lon, test_dl_lon)))\n",
    "\n",
    "y_t, y_p = make_minibatch_y(net_lat, net_lon, test_dl_lat, test_dl_lon)\n",
    "print(compare_results(y_t, y_p))\n",
    "show_error_distribution(y_t, y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad0eea8-c901-4591-b26e-18fdc4e4a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_loss_graph(n_epochs, train_loss_history_lat, test_loss_history_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dc332b-29b2-4dda-8e65-ba40dde12541",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_loss_graph(n_epochs, train_loss_history_lon, test_loss_history_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77acaf39-ad90-4bed-8f40-347dcc0e1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "77%\n",
    "79%\n",
    "78%\n",
    "83%\n",
    "74%\n",
    "79%\n",
    "\n",
    "\n",
    "\n",
    "82%\n",
    "77%\n",
    "81%\n",
    "70%\n",
    "76%\n",
    "75%\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b94a418-5802-4939-8910-370cd31a6c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a1e4a-1abc-4b17-a775-54287aaf50a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ccea8e-0c1c-40a6-8b49-b0b228804c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b1f45b-7997-4e2e-9cea-acce4af96a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3baf41c-f79b-44de-8d3b-815dd8b47a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a737cd4c-c12c-4300-9ea6-4a8ee2d7cc49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c571d5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf5ef6-27d9-4953-b17e-75536caea369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf469d2-8e91-4d4d-8d50-226bd75f1e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f85f3a0-1214-4709-94ff-3b64f358c7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca53d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa05ca31-e02f-4159-b895-40af9c16fa72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9229fdd-b4ed-42bf-8e36-c8ed9984c8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2d3423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de89910b-834e-406f-9e36-a4e8f1f31655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd28d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6571d9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d65453b-2697-4808-b227-03779eb01382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9820dc40-270e-4411-b57f-8f3217a75168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
